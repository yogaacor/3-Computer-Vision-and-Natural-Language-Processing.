# Computer-Vision-and-Natural-Language-Processing.
# 1. Enhancing Low-Light Images Using Max Pooling and CLAHE

This project focuses on improving the quality of low-light images by replicating techniques used in advanced smartphone cameras, such as Apple's Deep Fusion and Samsung's Adaptive Tetra-squared Pixel Sensor. The primary goal is to brighten dark images using Max Pooling, which combines adjacent pixels to enhance brightness. The results are then compared to the Contrast Limited Adaptive Histogram Equalization (CLAHE) technique, another popular method for enhancing low-light images.

The objective of this project is to:

- Implement the Max Pooling operation to brighten dark images, mimicking the functionality found in modern smartphone camera technologies.

- Compare the effectiveness of Max Pooling with CLAHE in enhancing low-light images.

- Analyze and visualize the improvements in image quality using these enhancement techniques.

# 2. Transfer Learning With Pre-trained CNN Models for Handwritten Digit Classification

This project aims to utilize Transfer Learning with pre-trained Convolutional Neural Networks (CNNs) to classify handwritten digits from the MNIST dataset. The goal is to train a model that can accurately identify digits (0-9) using transfer learning from models pre-trained on ImageNet. The models tested include DenseNet, ResNet, and Vision Transformer (ViT). The project explores freezing layers, tuning hyperparameters, and comparing performance across different model architectures.

The objective of this project is to:

- Use a pre-trained model (DenseNet) on the MNIST dataset to classify handwritten digits.

- Experiment with hyperparameter tuning and layer freezing to optimize model performance.

- Compare performance between different pre-trained models, including ResNet and ViT.

- Visualize the training and validation performance to assess model accuracy.

# 3. Real-Time Object Detection on YouTube Videos Using YOLOv5

This project focuses on implementing real-time object detection using the YOLOv5 (You Only Look Once) model on YouTube videos. The goal is to test YOLOv5â€™s accuracy and performance by applying it to video data from three different YouTube URLs. Object detection is a critical task in computer vision, and YOLOv5 is a popular model for detecting objects in images and videos due to its speed and accuracy.

The objectives of this project are to:

- Test YOLOv5 on three YouTube video URLs to evaluate its object detection performance.
- Analyze and document the accuracy of YOLOv5 for real-time object detection in video frames.
- Answer any questions related to the implementation directly in the provided notebook.

# 4. Disaster Tweets Classification Using Fine-Tuned BERT

With the increasing accessibility of smartphones, people can now report real-time emergency events via platform X (formerly known as Twitter). This has made organizations like disaster relief agencies and news agencies increasingly interested in monitoring Twitter systematically. In this project, you will classify tweets as disaster-related or not using a fine-tuned BERT (Bidirectional Encoder Representations for Transformers) model.

The primary objectives of this project are to:

- Use BERT for fine-tuning to classify tweets on platform X into disaster-related or not.
  
Develop a model that can:
- Analyze communication patterns and public response in emergency situations.
- Enhance early warning systems based on social media data.
- Assist disaster relief organizations in optimizing their responses.
- Investigate the impact of social media on public perceptions of disasters.

